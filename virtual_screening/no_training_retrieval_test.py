"""
虚拟筛选无训练版本检索测试
直接使用Molformer和DECODE的embedding进行可视化和检索任务
"""

import os
import sys
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder
import umap
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import argparse
import json
from datetime import datetime
import yaml
import warnings
warnings.filterwarnings('ignore')

# 添加项目路径
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# 设置日志
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# 设置matplotlib字体
plt.rcParams['font.family'] = 'Times New Roman'
plt.rcParams['font.size'] = 12
sns.set_style("whitegrid")

# 颜色配置
COLORS = {
    'positive': '#e23e57',
    'negative': '#3f72af', 
    'targeted_cancer': '#FF6B6B',
    'chemo': '#4ECDC4',
    'noncancer': '#45B7D1',
    'background': '#lightgray'
}

class NoTrainingRetrievalTester:
    """无训练版本检索测试器"""
    
    def __init__(
        self,
        data_path: str,
        molformer_model_path: str = './Molformer/',
        decode_model_path: str = None,
        output_dir: str = 'results/no_training_retrieval',
        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
        random_seed: int = 42,
        visualization_methods: List[str] = ['tsne', 'umap'],
        remove_drug_duplicates: bool = False,
        duplicate_threshold: float = 1e-6,
        dose_values: List[float] = [1.0, 10.0], 
        **kwargs
    ):
        self.data_path = data_path
        self.molformer_model_path = molformer_model_path
        self.decode_model_path = decode_model_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.device = device
        self.random_seed = random_seed
        self.visualization_methods = visualization_methods
        self.remove_drug_duplicates = remove_drug_duplicates
        self.duplicate_threshold = duplicate_threshold
        self.dose_values = dose_values

        self._init_models()

        self.data = self._load_data()
        
        logger.info(f"No Training Retrieval Tester initialized:")
        logger.info(f"  Data path: {data_path}")
        logger.info(f"  Output dir: {output_dir}")
        logger.info(f"  Device: {device}")
        logger.info(f"  Visualization methods: {visualization_methods}")
        logger.info(f"  Data samples: {len(self.data)}")
        logger.info(f"  Remove drug duplicates: {remove_drug_duplicates}")
        logger.info(f"  Dose values for DECODE: {dose_values}")
    
    def _init_models(self):
        """初始化Molformer和DECODE模型"""
        try:
            from transformers import AutoTokenizer, AutoModel

            logger.info("Loading Molformer model...")
            self.molformer_tokenizer = AutoTokenizer.from_pretrained(
                self.molformer_model_path, trust_remote_code=True
            )
            self.molformer_model = AutoModel.from_pretrained(
                self.molformer_model_path, trust_remote_code=True
            ).to(self.device)
            self.molformer_model.eval()
            
            logger.info("✅ Molformer model loaded successfully")
            
        except Exception as e:
            logger.error(f"❌ Failed to load Molformer: {e}")
            raise
        
        self.decode_model = None
        if self.decode_model_path:
            try:
                logger.info("Loading DECODE (MultiModalMOAPredictor) model...")
                self.decode_model = self._load_decode_model()
                if self.decode_model:
                    self.decode_model = self.decode_model.to(self.device)
                    self.decode_model.eval()
                    logger.info("✅ DECODE model loaded successfully")
                else:
                    logger.warning("⚠️ DECODE model loading returned None")
            except Exception as e:
                logger.warning(f"⚠️ Failed to load DECODE: {e}")
                self.decode_model = None
    
    def _load_decode_model(self):
        """加载DECODE模型（即MultiModalMOAPredictor）"""
        try:
            if os.path.exists(self.decode_model_path):
                if self.decode_model_path.endswith('.ckpt'):
                    from models.distangle_multimodal.distangle_multimodal_moa_predictor import MultiModalMOAPredictor

                    model = MultiModalMOAPredictor.load_from_checkpoint(
                        self.decode_model_path, 
                        map_location=self.device
                    )
                    return model
                else:
                    logger.warning(f"Unsupported DECODE model format: {self.decode_model_path}")
                    return None
            else:
                logger.warning(f"DECODE model file not found: {self.decode_model_path}")
                return None
                
        except Exception as e:
            logger.warning(f"Failed to load DECODE model: {e}")
            return None
    
    def _load_data(self) -> pd.DataFrame:
        """加载数据"""
        logger.info(f"Loading data from {self.data_path}")
        
        if self.data_path.endswith('.csv'):
            data = pd.read_csv(self.data_path)
        elif self.data_path.endswith('.xlsx'):
            data = pd.read_excel(self.data_path)
        else:
            raise ValueError(f"Unsupported file format: {self.data_path}")
        
        logger.info(f"Loaded {len(data)} samples")
        logger.info(f"Columns: {list(data.columns)}")
        
        # 去重处理（如果启用）
        if self.remove_drug_duplicates:
            data = self._remove_duplicate_drugs_from_dataframe(data)
        
        return data
    
    def _remove_duplicate_drugs_from_dataframe(self, data: pd.DataFrame) -> pd.DataFrame:
        """从DataFrame中移除重复药物"""
        logger.info("🔍 检测并移除重复药物...")
        
        original_count = len(data)
        
        # 尝试基于SMILES去重
        smiles_columns = ['smiles', 'SMILES', 'canonical_smiles', 'Metadata_SMILES']
        smiles_column = None
        
        for col in smiles_columns:
            if col in data.columns:
                smiles_column = col
                break
        
        if smiles_column:
            logger.info(f"🧪 基于SMILES列去重: {smiles_column}")
            data_deduplicated = data.drop_duplicates(subset=[smiles_column], keep='first')
        else:
            logger.warning("⚠️ 未找到SMILES列，无法去重")
            return data
        
        removed_count = original_count - len(data_deduplicated)

        return data_deduplicated
    
    def extract_molformer_embeddings(self, smiles_list: List[str], batch_size: int = 32) -> torch.Tensor:
        """提取Molformer embeddings"""
        logger.info(f"Extracting Molformer embeddings for {len(smiles_list)} molecules...")
        
        all_embeddings = []
        
        with torch.no_grad():
            for i in range(0, len(smiles_list), batch_size):
                batch_smiles = smiles_list[i:i+batch_size]
                
                # Tokenize
                encoded = self.molformer_tokenizer(
                    batch_smiles,
                    return_tensors='pt',
                    padding=True,
                    truncation=True,
                    max_length=512
                ).to(self.device)
                
                # Forward pass
                outputs = self.molformer_model(**encoded)
                
                embeddings = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_dim]
                all_embeddings.append(embeddings.cpu())
                
                if (i // batch_size + 1) % 10 == 0:
                    logger.info(f"  Processed {i + len(batch_smiles)}/{len(smiles_list)} molecules")
        
        embeddings = torch.cat(all_embeddings, dim=0)
        logger.info(f"Extracted embeddings shape: {embeddings.shape}")
        
        return embeddings
    
    def extract_decode_embeddings(self, smiles_list: List[str], batch_size: int = 32) -> Optional[torch.Tensor]:
        if self.decode_model is None:
            logger.warning("DECODE model not available")
            return None
        
        logger.info(f"Extracting DECODE embeddings for {len(smiles_list)} molecules...")
        logger.info("Following SimplifiedDisentangledVirtualScreeningModule feature extraction pipeline:")
        logger.info("Step 1: Extract Molformer drug features")
        logger.info("Step 2: Use both_missing scenario to get disentangled features")
        logger.info("Step 3: Average across multiple dose values")
        
        all_embeddings = []
        
        with torch.no_grad():
            for i in range(0, len(smiles_list), batch_size):
                batch_smiles = smiles_list[i:i+batch_size]
                
                try:
                    molformer_drug_features = self._extract_molformer_drug_features_for_decode(batch_smiles)

                    batch_embeddings = self._extract_disentangled_features_from_molformer(
                        molformer_drug_features, len(batch_smiles)
                    )
                    
                    if batch_embeddings is not None:
                        all_embeddings.append(batch_embeddings.cpu())
                    
                    if (i // batch_size + 1) % 10 == 0:
                        logger.info(f"  Processed {i + len(batch_smiles)}/{len(smiles_list)} molecules")
                        
                except Exception as e:
                    logger.error(f"Error processing batch {i//batch_size}: {e}")
                    continue
        
        if all_embeddings:
            embeddings = torch.cat(all_embeddings, dim=0)
            logger.info(f"Extracted DECODE embeddings shape: {embeddings.shape}")
            return embeddings
        else:
            logger.warning("No DECODE embeddings extracted")
            return None
    
    def _extract_molformer_drug_features_for_decode(self, smiles_list: List[str]) -> torch.Tensor:
        """为DECODE提取Molformer药物特征（模仿SimplifiedDisentangledVirtualScreeningModule的_encode_smiles_to_drug_features方法）"""

        encoded = self.molformer_tokenizer(
            smiles_list,
            return_tensors='pt',
            padding=True,
            truncation=True,
            max_length=512
        ).to(self.device)

        outputs = self.molformer_model(**encoded)

        drug_features = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_dim]
        
        logger.debug(f"Extracted Molformer drug features shape: {drug_features.shape}")
        return drug_features
    
    def _extract_disentangled_features_from_molformer(self, drug_features: torch.Tensor, batch_size: int) -> Optional[torch.Tensor]:
        """使用解耦模型从Molformer特征提取both_missing场景的特征（模仿SimplifiedDisentangledVirtualScreeningModule的_extract_disentangled_features方法）"""
        device = drug_features.device

        all_disentangled_features = []
        
        try:
            for dose_value in self.dose_values:
                logger.debug(f"Processing dose value: {dose_value}")
     
                batch_data = {
                    'drug': drug_features,
                    'dose': torch.full((batch_size, 1), dose_value).to(device),
                    'rna': torch.zeros(batch_size, self.decode_model.rna_dim).to(device), 
                    'pheno': torch.zeros(batch_size, self.decode_model.pheno_dim).to(device) 
                }

                predictions = self.decode_model(batch_data, missing_scenarios=['both_missing'])
                
                if 'both_missing' not in predictions:
                    logger.warning(f"both_missing scenario not found in predictions for dose {dose_value}")
                    continue
                
                both_missing_result = predictions['both_missing']

                if 'fused_features' in both_missing_result:
                    fused_features = both_missing_result['fused_features']
                    all_disentangled_features.append(fused_features)
                    logger.debug(f"Extracted fused_features shape for dose {dose_value}: {fused_features.shape}")
                else:
                    logger.warning(f"fused_features not found in both_missing result for dose {dose_value}")

            if len(all_disentangled_features) > 1:
                final_disentangled_features = torch.stack(all_disentangled_features, dim=0).mean(dim=0)
                logger.debug(f"Averaged features across {len(all_disentangled_features)} dose values")
            elif len(all_disentangled_features) == 1:
                final_disentangled_features = all_disentangled_features[0]
                logger.debug("Using single dose features")
            else:
                logger.error("No disentangled features extracted for any dose value")
                return None
            
            return final_disentangled_features
            
        except Exception as e:
            logger.error(f"Error in _extract_disentangled_features_from_molformer: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def create_binary_classification_visualization(self, embeddings: torch.Tensor, 
                                                 labels: np.ndarray, 
                                                 method: str = 'tsne') -> plt.Figure:
        """创建二元分类可视化"""
        logger.info(f"Creating binary classification visualization using {method.upper()}...")
        
        embeddings_np = embeddings.cpu().numpy()
        if method == 'tsne':
            reducer = TSNE(n_components=2, perplexity=30, random_state=self.random_seed)
        elif method == 'umap':
            reducer = umap.UMAP(n_components=2, random_state=self.random_seed)
        else:
            raise ValueError(f"Unsupported method: {method}")

        if embeddings_np.shape[1] > 50:
            pca = PCA(n_components=50, random_state=self.random_seed)
            embeddings_np = pca.fit_transform(embeddings_np)
            logger.info(f"PCA reduced features from {embeddings.shape[1]} to 50 dimensions")
        
        reduced_features = reducer.fit_transform(embeddings_np)

        fig, ax = plt.subplots(figsize=(10, 8))

        positive_mask = labels == 1
        negative_mask = labels == 0

        ax.scatter(reduced_features[negative_mask, 0], reduced_features[negative_mask, 1],
                  c=COLORS['negative'], alpha=0.6, s=50, label=f'Negative (n={negative_mask.sum()})')

        ax.scatter(reduced_features[positive_mask, 0], reduced_features[positive_mask, 1],
                  c=COLORS['positive'], alpha=0.8, s=60, label=f'Positive (n={positive_mask.sum()})')
        
        ax.set_title(f'Binary Classification Visualization ({method.upper()})\n'
                    f'Molformer Embeddings', fontsize=14, fontweight='bold')
        ax.set_xlabel(f'{method.upper()}-1', fontsize=12)
        ax.set_ylabel(f'{method.upper()}-2', fontsize=12)
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig
    
    def create_moa_visualization(self, embeddings: torch.Tensor, 
                               moa_labels: List[str], 
                               method: str = 'tsne',
                               max_moas: int = 10) -> plt.Figure:
        """创建MOA类别可视化"""
        logger.info(f"Creating MOA visualization using {method.upper()}...")
        
        embeddings_np = embeddings.cpu().numpy()
        

        label_encoder = LabelEncoder()
        encoded_moa_labels = label_encoder.fit_transform(moa_labels)
        
        logger.info(f"MOA类别编码:")
        for i, moa in enumerate(label_encoder.classes_):
            count = (encoded_moa_labels == i).sum()
            logger.info(f"  {i}: {moa} ({count} samples)")
        

        if method == 'tsne':
            reducer = TSNE(n_components=2, perplexity=30, random_state=self.random_seed)
        elif method == 'umap':
            reducer = umap.UMAP(n_components=2, random_state=self.random_seed)
        else:
            raise ValueError(f"Unsupported method: {method}")
        
        if embeddings_np.shape[1] > 50:
            pca = PCA(n_components=50, random_state=self.random_seed)
            embeddings_np = pca.fit_transform(embeddings_np)
        
        reduced_features = reducer.fit_transform(embeddings_np)

        unique_moas, counts = np.unique(encoded_moa_labels, return_counts=True)
        
        top_moa_indices = np.argsort(counts)[::-1][:max_moas]
        top_moa_codes = unique_moas[top_moa_indices]
        

        fig, ax = plt.subplots(figsize=(12, 9))
        

        colors = plt.cm.tab10(np.linspace(0, 1, len(top_moa_codes)))
        
        other_mask = ~np.isin(encoded_moa_labels, top_moa_codes)
        if other_mask.sum() > 0:
            ax.scatter(reduced_features[other_mask, 0], reduced_features[other_mask, 1],
                      c=COLORS['background'], alpha=0.4, s=30, label='Other MOAs')

        for i, moa_code in enumerate(top_moa_codes):
            moa_mask = encoded_moa_labels == moa_code
            count = moa_mask.sum()
            moa_name = label_encoder.classes_[moa_code]
            
            ax.scatter(reduced_features[moa_mask, 0], reduced_features[moa_mask, 1],
                      c=[colors[i]], alpha=0.8, s=60, 
                      label=f'{moa_name} (n={count})')
        
        ax.set_title(f'MOA Classification Visualization ({method.upper()})\n'
                    f'Top {len(top_moa_codes)} MOAs - Molformer Embeddings', 
                    fontsize=14, fontweight='bold')
        ax.set_xlabel(f'{method.upper()}-1', fontsize=12)
        ax.set_ylabel(f'{method.upper()}-2', fontsize=12)
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig
    
    def run_drug_category_retrieval(self) -> Dict[str, Any]:
        logger.info("🚀 Starting enhanced drug category retrieval task...")
        logger.info("Following SimplifiedDisentangledVirtualScreeningModule pipeline for DECODE features")
        logger.info("Using label100=1 as ground truth for accuracy assessment")

        required_columns = ['smiles', 'label100']
        missing_columns = [col for col in required_columns if col not in self.data.columns]
        if missing_columns:
            logger.error(f"Missing required columns: {missing_columns}")
            return {}

        drug_category_column = None
        possible_category_columns = ['drug_category', 'category', 'Drug_Category', 'type']
        for col in possible_category_columns:
            if col in self.data.columns:
                drug_category_column = col
                break
        
        if drug_category_column is None:
            logger.warning("No drug category column found, creating artificial categories based on activity")
            self.data['drug_category'] = self.data.get('label100', 0).apply(
                lambda x: 'targeted cancer' if x == 1 else 'noncancer'
            )
            drug_category_column = 'drug_category'

        smiles_list = self.data['smiles'].tolist()
        drug_categories = self.data[drug_category_column].tolist()
        labels_100 = self.data['label100'].values  

        cancer_drug_mask = []
        for cat in drug_categories:
            cat_lower = str(cat).lower()
            cancer_drug_mask.append(any(term in cat_lower for term in ['targeted cancer', 'chemo']))
        
        cancer_drug_mask = np.array(cancer_drug_mask)

        positive_query_mask = cancer_drug_mask & (labels_100 == 1)
        negative_samples_mask = labels_100 == 0  
        
        logger.info(f"Cancer drug samples: {cancer_drug_mask.sum()}")
        logger.info(f"Positive query samples (cancer drugs with label100=1): {positive_query_mask.sum()}")
        logger.info(f"Negative database samples (label100=0): {negative_samples_mask.sum()}")
        
        if positive_query_mask.sum() == 0:
            logger.error("No positive query samples found (cancer drugs with label100=1)")
            return {}
        
        if negative_samples_mask.sum() == 0:
            logger.error("No negative database samples found (label100=0)")
            return {}

        logger.info("Extracting Molformer embeddings...")
        molformer_embeddings = self.extract_molformer_embeddings(smiles_list)
        
        decode_embeddings = None
        if self.decode_model:
            logger.info("Extracting DECODE embeddings using SimplifiedDisentangledVirtualScreeningModule pipeline...")
            decode_embeddings = self.extract_decode_embeddings(smiles_list)
        
        if decode_embeddings is None:
            logger.error("DECODE model is required for this analysis but not available")
            return {}
        
        results = {}

        embedding_types = [
            ('molformer', molformer_embeddings),
            ('decode', decode_embeddings),
            ('combined', torch.cat([molformer_embeddings, decode_embeddings], dim=1))
        ]
        
        for embedding_name, embeddings in embedding_types:
            logger.info(f"\n🔬 Processing {embedding_name} embeddings...")

            query_embeddings = embeddings[positive_query_mask]
            database_embeddings = embeddings[negative_samples_mask]

            query_labels = np.ones(query_embeddings.shape[0])  
            database_labels = np.zeros(database_embeddings.shape[0])  
            
            logger.info(f"Query embeddings: {query_embeddings.shape}")
            logger.info(f"Database embeddings: {database_embeddings.shape}")
            

            if len(query_embeddings) > 0 and len(database_embeddings) > 0:
                metrics = self.compute_retrieval_metrics(
                    query_embeddings, database_embeddings,
                    query_labels, database_labels
                )
                
                logger.info(f"{embedding_name} retrieval metrics:")
                for metric_name, metric_value in metrics.items():
                    logger.info(f"  {metric_name}: {metric_value:.4f}")
            else:
                logger.warning(f"Insufficient data for {embedding_name} retrieval task")
                metrics = {}
            
            results[embedding_name] = {
                'metrics': metrics,
                'query_samples': positive_query_mask.sum(),
                'database_samples': negative_samples_mask.sum()
            }
        
        visualizations = {}
        for method in self.visualization_methods:
            try:
                fig = self.create_dual_model_visualization(
                    molformer_embeddings, decode_embeddings, labels_100, method
                )
                
                viz_file = self.output_dir / f'dual_model_retrieval_{method}.png'
                fig.savefig(viz_file, dpi=300, bbox_inches='tight')
                plt.close(fig)
                visualizations[method] = str(viz_file)
                logger.info(f"Dual model {method.upper()} visualization saved to: {viz_file}")
            except Exception as e:
                logger.error(f"Error creating {method} visualization: {e}")
        
        return {
            'embedding_results': results,
            'visualizations': visualizations,
            'data_stats': {
                'total_samples': len(self.data),
                'cancer_drug_samples': cancer_drug_mask.sum(),
                'positive_query_samples': positive_query_mask.sum(),
                'negative_database_samples': negative_samples_mask.sum()
            }
        }
    
    def create_dual_model_visualization(self, molformer_embeddings: torch.Tensor,
                                      decode_embeddings: torch.Tensor,
                                      labels: np.ndarray,
                                      method: str = 'tsne') -> plt.Figure:
        logger.info(f"Creating dual model visualization using {method.upper()}...")

        fig, axes = plt.subplots(1, 2, figsize=(16, 8))
        
        embeddings_list = [
            (molformer_embeddings, "Molformer", axes[0]),
            (decode_embeddings, "DECODE", axes[1])
        ]
        
        for embeddings, title, ax in embeddings_list:
            embeddings_np = embeddings.cpu().numpy()

            if method == 'tsne':
                reducer = TSNE(n_components=2, perplexity=30, random_state=self.random_seed)
            elif method == 'umap':
                reducer = umap.UMAP(n_components=2, random_state=self.random_seed)
            else:
                raise ValueError(f"Unsupported method: {method}")

            if embeddings_np.shape[1] > 50:
                pca = PCA(n_components=50, random_state=self.random_seed)
                embeddings_np = pca.fit_transform(embeddings_np)
            
            reduced_features = reducer.fit_transform(embeddings_np)

            positive_mask = labels == 1
            negative_mask = labels == 0

            ax.scatter(reduced_features[negative_mask, 0], reduced_features[negative_mask, 1],
                      c=COLORS['negative'], alpha=0.6, s=50, label=f'Negative (n={negative_mask.sum()})')

            ax.scatter(reduced_features[positive_mask, 0], reduced_features[positive_mask, 1],
                      c=COLORS['positive'], alpha=0.8, s=60, label=f'Positive (n={positive_mask.sum()})')
            
            ax.set_title(f'{title} ({method.upper()})', fontsize=14, fontweight='bold')
            ax.set_xlabel(f'{method.upper()}-1', fontsize=12)
            ax.set_ylabel(f'{method.upper()}-2', fontsize=12)
            ax.legend(fontsize=10)
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Dual Model Comparison - Cancer Drug Retrieval ({method.upper()})', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        return fig

    def compute_retrieval_metrics(self, query_features: torch.Tensor, 
                                database_features: torch.Tensor,
                                query_labels: np.ndarray,
                                database_labels: np.ndarray) -> Dict[str, float]:
        """计算检索指标 - 扩展到recall@20"""
        logger.info("Computing retrieval metrics...")

        query_features = F.normalize(query_features, dim=-1)
        database_features = F.normalize(database_features, dim=-1)

        similarity_matrix = torch.mm(query_features, database_features.t())
        
        metrics = {}

        k_values = [1, 5, 10, 15, 20]
        all_recalls = {k: [] for k in k_values}
        all_precisions = {k: [] for k in k_values}
        all_aps = []
        all_rrs = []
        all_enrichments = []
        
        for i in range(len(query_features)):
            query_label = query_labels[i]
            similarities = similarity_matrix[i]
            
            _, sorted_indices = torch.sort(similarities, descending=True)
            retrieved_labels = database_labels[sorted_indices.cpu().numpy()]
            

            relevance = (retrieved_labels == query_label).astype(float)
            num_relevant = relevance.sum()
            
            if num_relevant == 0:
                continue
            
            # Recall@K
            for k in k_values:
                if k <= len(retrieved_labels):
                    recall_k = relevance[:k].sum() / max(num_relevant, 1)
                    all_recalls[k].append(recall_k)
            
            # Precision@K
            for k in k_values:
                if k <= len(retrieved_labels):
                    precision_k = relevance[:k].sum() / k
                    all_precisions[k].append(precision_k)
            
            # Average Precision
            precisions = []
            for j in range(len(retrieved_labels)):
                if relevance[j] == 1:
                    precision_at_j = relevance[:j+1].sum() / (j + 1)
                    precisions.append(precision_at_j)
            
            if precisions:
                ap = np.mean(precisions)
                all_aps.append(ap)
            
            # Reciprocal Rank
            first_relevant = np.where(relevance == 1)[0]
            if len(first_relevant) > 0:
                rr = 1.0 / (first_relevant[0] + 1)
                all_rrs.append(rr)
            
            # Enrichment Factor @10%
            top_10_percent = max(1, int(len(retrieved_labels) * 0.1))
            expected_rate = num_relevant / len(retrieved_labels)
            actual_rate = relevance[:top_10_percent].sum() / top_10_percent
            if expected_rate > 0:
                enrichment = actual_rate / expected_rate
                all_enrichments.append(enrichment)

        for k in k_values:
            if all_recalls[k]:
                metrics[f'recall_at_{k}'] = np.mean(all_recalls[k])
            if all_precisions[k]:
                metrics[f'precision_at_{k}'] = np.mean(all_precisions[k])
        
        if all_aps:
            metrics['mean_average_precision'] = np.mean(all_aps)
        
        if all_rrs:
            metrics['mean_reciprocal_rank'] = np.mean(all_rrs)
        
        if all_enrichments:
            metrics['enrichment_factor'] = np.mean(all_enrichments)
        

        separation_metrics = self._compute_separation_metrics(query_features, database_features)
        metrics.update(separation_metrics)
        
        return metrics

    def _compute_separation_metrics(self, positive_features: torch.Tensor, 
                                  negative_features: torch.Tensor) -> Dict[str, float]:

        pos_center = positive_features.mean(dim=0)
        neg_center = negative_features.mean(dim=0)

        inter_class_distance = torch.norm(pos_center - neg_center).item()

        pos_intra_distance = torch.norm(positive_features - pos_center.unsqueeze(0), dim=1).mean().item()
        neg_intra_distance = torch.norm(negative_features - neg_center.unsqueeze(0), dim=1).mean().item()
        avg_intra_distance = (pos_intra_distance + neg_intra_distance) / 2

        separation_ratio = inter_class_distance / (avg_intra_distance + 1e-8)

        all_features = torch.cat([positive_features, negative_features], dim=0)
        all_labels = torch.cat([
            torch.ones(len(positive_features)), 
            torch.zeros(len(negative_features))
        ], dim=0)

        all_features_norm = F.normalize(all_features, dim=-1)
        similarity_matrix = torch.mm(all_features_norm, all_features_norm.t())
        
        correct_predictions = 0
        total_predictions = len(all_features)
        
        for i in range(len(all_features)):
            similarities = similarity_matrix[i]
            similarities[i] = -1 
            
            nearest_neighbor_idx = torch.argmax(similarities).item()
            if all_labels[i] == all_labels[nearest_neighbor_idx]:
                correct_predictions += 1
        
        nearest_neighbor_accuracy = correct_predictions / total_predictions
        
        return {
            'inter_class_distance': inter_class_distance,
            'avg_intra_class_distance': avg_intra_distance,
            'separation_ratio': separation_ratio,
            'nearest_neighbor_accuracy': nearest_neighbor_accuracy
        }

    def run_binary_classification_analysis(self) -> Dict[str, Any]:
        """运行二元分类分析 - 同时处理两个模型"""

        label_column = None
        possible_label_columns = ['label', 'label100', 'activity', 'active']
        for col in possible_label_columns:
            if col in self.data.columns:
                label_column = col
                break
        
        if label_column is None:
            logger.error(f"No label column found. Looked for: {possible_label_columns}")
            return {}

        smiles_list = self.data['smiles'].tolist()
        labels = self.data[label_column].values

        logger.info("Extracting Molformer embeddings...")
        molformer_embeddings = self.extract_molformer_embeddings(smiles_list)
        
        decode_embeddings = None
        if self.decode_model:
            logger.info("Extracting DECODE embeddings...")
            decode_embeddings = self.extract_decode_embeddings(smiles_list)

        visualizations = {}
        for method in self.visualization_methods:
            try:
                if decode_embeddings is not None:
                    fig = self.create_dual_model_visualization(
                        molformer_embeddings, decode_embeddings, labels, method
                    )
                    viz_file = self.output_dir / f'binary_classification_dual_model_{method}.png'
                    
                    logger.info(f"Binary classification dual model {method.upper()} visualization saved to: {viz_file}")
                else:

                    fig = self.create_binary_classification_visualization(molformer_embeddings, labels, method)
                    viz_file = self.output_dir / f'binary_classification_{method}.png'
                    
                    logger.info(f"Binary classification {method.upper()} visualization saved to: {viz_file}")
                
                fig.savefig(viz_file, dpi=300, bbox_inches='tight')
                plt.close(fig)
                visualizations[method] = str(viz_file)
                
            except Exception as e:
                logger.error(f"Error creating {method} visualization: {e}")

        unique_labels, counts = np.unique(labels, return_counts=True)
        label_distribution = dict(zip(unique_labels.astype(str), counts.astype(int)))
        
        return {
            'visualizations': visualizations,
            'label_distribution': label_distribution,
            'label_column': label_column,
            'models_used': ['molformer', 'decode'] if decode_embeddings is not None else ['molformer']
        }
    
    def run_moa_analysis(self) -> Dict[str, Any]:
        """运行MOA分析 - 同时处理两个模型"""
        logger.info("🧬 Starting MOA analysis...")

        moa_column = None
        possible_moa_columns = ['moa', 'MOA', 'mechanism', 'target']
        for col in possible_moa_columns:
            if col in self.data.columns:
                moa_column = col
                break
        
        if moa_column is None:
            logger.warning(f"No MOA column found. Looked for: {possible_moa_columns}")
            return {}
        

        smiles_list = self.data['smiles'].tolist()
        moa_labels = self.data[moa_column].tolist()

        logger.info("Extracting Molformer embeddings...")
        molformer_embeddings = self.extract_molformer_embeddings(smiles_list)
        
        decode_embeddings = None
        if self.decode_model:
            logger.info("Extracting DECODE embeddings...")
            decode_embeddings = self.extract_decode_embeddings(smiles_list)

        visualizations = {}
        for method in self.visualization_methods:
            try:
                if decode_embeddings is not None:
                    fig = self.create_dual_model_moa_visualization(
                        molformer_embeddings, decode_embeddings, moa_labels, method
                    )
                    viz_file = self.output_dir / f'moa_analysis_dual_model_{method}.png'
                    
                    logger.info(f"MOA dual model {method.upper()} visualization saved to: {viz_file}")
                else:
                    fig = self.create_moa_visualization(molformer_embeddings, moa_labels, method)
                    viz_file = self.output_dir / f'moa_analysis_{method}.png'
                    
                    logger.info(f"MOA {method.upper()} visualization saved to: {viz_file}")
                
                fig.savefig(viz_file, dpi=300, bbox_inches='tight')
                plt.close(fig)
                visualizations[method] = str(viz_file)
                
            except Exception as e:
                logger.error(f"Error creating {method} visualization: {e}")
        
        unique_moas, counts = np.unique(moa_labels, return_counts=True)
        moa_distribution = dict(zip(unique_moas.astype(str), counts.astype(int)))
        
        return {
            'visualizations': visualizations,
            'moa_distribution': moa_distribution,
            'moa_column': moa_column,
            'unique_moas': len(unique_moas),
            'models_used': ['molformer', 'decode'] if decode_embeddings is not None else ['molformer']
        }
    
    def create_dual_model_moa_visualization(self, molformer_embeddings: torch.Tensor,
                                          decode_embeddings: torch.Tensor,
                                          moa_labels: List[str],
                                          method: str = 'tsne',
                                          max_moas: int = 10) -> plt.Figure:
        """创建双模型MOA对比可视化"""
        logger.info(f"Creating dual model MOA visualization using {method.upper()}...")

        label_encoder = LabelEncoder()
        encoded_moa_labels = label_encoder.fit_transform(moa_labels)
        
        logger.info(f"MOA类别编码:")
        for i, moa in enumerate(label_encoder.classes_):
            count = (encoded_moa_labels == i).sum()
            logger.info(f"  {i}: {moa} ({count} samples)")

        fig, axes = plt.subplots(1, 2, figsize=(20, 9))
        
        embeddings_list = [
            (molformer_embeddings, "Molformer", axes[0]),
            (decode_embeddings, "DECODE", axes[1])
        ]
        
        for embeddings, title, ax in embeddings_list:
            embeddings_np = embeddings.cpu().numpy()
            
            if method == 'tsne':
                reducer = TSNE(n_components=2, perplexity=30, random_state=self.random_seed)
            elif method == 'umap':
                reducer = umap.UMAP(n_components=2, random_state=self.random_seed)
            else:
                raise ValueError(f"Unsupported method: {method}")
 
            if embeddings_np.shape[1] > 50:
                pca = PCA(n_components=50, random_state=self.random_seed)
                embeddings_np = pca.fit_transform(embeddings_np)
            
            reduced_features = reducer.fit_transform(embeddings_np)
            
            unique_moas, counts = np.unique(encoded_moa_labels, return_counts=True)
            
            top_moa_indices = np.argsort(counts)[::-1][:max_moas]
            top_moa_codes = unique_moas[top_moa_indices]
            colors = plt.cm.tab10(np.linspace(0, 1, len(top_moa_codes)))
            
            other_mask = ~np.isin(encoded_moa_labels, top_moa_codes)
            if other_mask.sum() > 0:
                ax.scatter(reduced_features[other_mask, 0], reduced_features[other_mask, 1],
                          c=COLORS['background'], alpha=0.4, s=30, label='Other MOAs')
            
            for i, moa_code in enumerate(top_moa_codes):
                moa_mask = encoded_moa_labels == moa_code
                count = moa_mask.sum()
                moa_name = label_encoder.classes_[moa_code]
                
                ax.scatter(reduced_features[moa_mask, 0], reduced_features[moa_mask, 1],
                          c=[colors[i]], alpha=0.8, s=60, 
                          label=f'{moa_name} (n={count})')
            
            ax.set_title(f'{title} - MOA Classification ({method.upper()})', 
                        fontsize=14, fontweight='bold')
            ax.set_xlabel(f'{method.upper()}-1', fontsize=12)
            ax.set_ylabel(f'{method.upper()}-2', fontsize=12)
            
            # 图例放在右侧
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Dual Model MOA Classification Comparison ({method.upper()})\n'
                    f'Top {len(top_moa_codes)} MOAs', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        return fig

    def run_complete_analysis(self) -> Dict[str, Any]:
        logger.info("🚀 Starting enhanced no-training retrieval analysis...")
        
        results = {
            'analysis_info': {
                'data_path': self.data_path,
                'output_dir': str(self.output_dir),
                'device': self.device,
                'random_seed': self.random_seed,
                'visualization_methods': self.visualization_methods,
                'timestamp': datetime.now().isoformat(),
                'molformer_available': True,
                'decode_available': self.decode_model is not None,
                'remove_drug_duplicates': self.remove_drug_duplicates
            }
        }
        
        try:
            binary_results = self.run_binary_classification_analysis()
            results['binary_classification'] = binary_results
            logger.info("✅ Binary classification analysis completed")
        except Exception as e:
            logger.error(f"❌ Binary classification analysis failed: {e}")
        
        try:
            moa_results = self.run_moa_analysis()
            results['moa_analysis'] = moa_results
            logger.info("✅ MOA analysis completed")
        except Exception as e:
            logger.error(f"❌ MOA analysis failed: {e}")
        try:
            drug_category_results = self.run_drug_category_retrieval()
            results['drug_category_retrieval'] = drug_category_results
            logger.info("✅ Enhanced drug category retrieval completed")
        except Exception as e:
            logger.error(f"❌ Drug category retrieval failed: {e}")
        
        return results
    
    def save_results(self, results: Dict[str, Any]) -> str:
        logger.info("💾 Saving enhanced results...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = self.output_dir / f'no_training_retrieval_results_{timestamp}.json'
        
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        self._create_enhanced_summary_report(results, timestamp)
        
        logger.info(f"Results saved to: {results_file}")
        return str(results_file)
    
    def _create_enhanced_summary_report(self, results: Dict[str, Any], timestamp: str):
        report_file = self.output_dir / f'enhanced_analysis_summary_{timestamp}.txt'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ENHANCED NO-TRAINING RETRIEVAL ANALYSIS SUMMARY REPORT\n")
            f.write("=" * 80 + "\n")
            f.write(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Data path: {self.data_path}\n")
            f.write(f"Total samples: {len(self.data)}\n")
            f.write(f"Molformer available: {results['analysis_info']['molformer_available']}\n")
            f.write(f"DECODE available: {results['analysis_info']['decode_available']}\n")
            f.write(f"Drug duplicates removed: {results['analysis_info']['remove_drug_duplicates']}\n")
            f.write(f"DECODE dose values: {self.dose_values}\n")
            f.write(f"DECODE pipeline: SimplifiedDisentangledVirtualScreeningModule-based\n")
            f.write(f"Retrieval evaluation: Query=cancer drugs with label100=1, Database=samples with label100=0\n\n")
            
            # 药物类别检索结果对比
            if 'drug_category_retrieval' in results and 'embedding_results' in results['drug_category_retrieval']:
                f.write("DUAL MODEL RETRIEVAL RESULTS COMPARISON\n")
                f.write("-" * 50 + "\n")
                
                embedding_results = results['drug_category_retrieval']['embedding_results']
                
                f.write("Model Performance Comparison:\n")
                f.write(f"{'Model':<15} {'Recall@1':<10} {'Recall@5':<10} {'Recall@20':<10} {'NN_Acc':<10} {'Sep_Ratio':<12}\n")
                f.write("-" * 80 + "\n")
                
                for embedding_name, embedding_result in embedding_results.items():
                    metrics = embedding_result.get('metrics', {})
                    recall_1 = metrics.get('recall_at_1', 0)
                    recall_5 = metrics.get('recall_at_5', 0)
                    recall_20 = metrics.get('recall_at_20', 0)
                    nn_acc = metrics.get('nearest_neighbor_accuracy', 0)
                    sep_ratio = metrics.get('separation_ratio', 0)
                    
                    f.write(f"{embedding_name:<15} {recall_1:<10.4f} {recall_5:<10.4f} {recall_20:<10.4f} {nn_acc:<10.4f} {sep_ratio:<12.4f}\n")
                
                # 找出最佳模型
                best_model = None
                best_nn_acc = 0
                for embedding_name, embedding_result in embedding_results.items():
                    nn_acc = embedding_result.get('metrics', {}).get('nearest_neighbor_accuracy', 0)
                    if nn_acc > best_nn_acc:
                        best_nn_acc = nn_acc
                        best_model = embedding_name
                
                if best_model:
                    f.write(f"\nBest performing model: {best_model} (NN Accuracy: {best_nn_acc:.4f})\n")
                
                # 数据统计
                if 'data_stats' in results['drug_category_retrieval']:
                    stats = results['drug_category_retrieval']['data_stats']
                    f.write(f"\nData Distribution:\n")
                    f.write(f"  Total samples: {stats.get('total_samples', 0)}\n")
                    f.write(f"  Cancer drug samples: {stats.get('cancer_drug_samples', 0)}\n")
                    f.write(f"  Positive query samples (cancer + label100=1): {stats.get('positive_query_samples', 0)}\n")
                    f.write(f"  Negative database samples (label100=0): {stats.get('negative_database_samples', 0)}\n")
            
            f.write("\n" + "=" * 80 + "\n")
            f.write("KEY FINDINGS:\n")
            f.write("- Both Molformer and DECODE models evaluated simultaneously\n")
            f.write("- Retrieval accuracy determined by label100=1 ground truth\n")
            f.write("- Query samples: cancer drugs with confirmed activity (label100=1)\n")
            f.write("- Database samples: all inactive compounds (label100=0)\n")
            f.write("- Separation metrics measure feature space discrimination\n")
            f.write("- Nearest neighbor accuracy indicates clustering quality\n")
            f.write("- DECODE features extracted using both_missing scenario\n")
            f.write("- Combined features may enhance discrimination capability\n")
            if results['analysis_info']['decode_available']:
                f.write("- DECODE model successfully integrated for comparison\n")
            else:
                f.write("- DECODE model not available - using Molformer only\n")
            f.write("=" * 80 + "\n")
        
        logger.info(f"📄 Enhanced summary report saved to: {report_file}")


def main():
    """主函数"""
    parser = argparse.ArgumentParser(description='Enhanced No-Training Retrieval Analysis for Virtual Screening')
    parser.add_argument('--data_path', type=str, 
                       default='preprocessed_data/Virtual_screening/Cancer/ChEMBL-Cancer_processed_ac.csv')
    parser.add_argument('--molformer_model_path', type=str, 
                       default='./Molformer/',
                       help='Path to Molformer model')
    parser.add_argument('--decode_model_path', type=str,
                       default='results_distangle/multimodal_lincs_plate/20250825_212437/split_0/stage1/checkpoints_stage1/stage1-multimodal-moa-56-46.405534.ckpt',
                       help='Path to DECODE (MultiModalMOAPredictor) model')
    parser.add_argument('--output_dir', type=str,
                       default='results/no_training_retrieval',
                       help='Output directory for results')
    parser.add_argument('--device', type=str, default='auto',
                       help='Device to use (auto, cuda, cpu)')
    parser.add_argument('--random_seed', type=int, default=42,
                       help='Random seed for reproducibility')
    parser.add_argument('--visualization_methods', nargs='+',
                       default=['tsne', 'umap'],
                       help='Visualization methods to use')
    parser.add_argument('--remove_drug_duplicates', action='store_true',
                       help='Remove duplicate drug samples')
    parser.add_argument('--duplicate_threshold', type=float, default=1e-6,
                       help='Threshold for duplicate detection')
    parser.add_argument('--dose_values', nargs='+', type=float,
                       default=[1.0, 10.0],
                       help='Dose values for DECODE feature averaging')
    
    args = parser.parse_args()
    
    # 设置设备
    if args.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = args.device
    
    logger.info(f"Using device: {device}")
    logger.info(f"DECODE dose values: {args.dose_values}")
    
    # 检查数据文件
    if not os.path.exists(args.data_path):
        logger.error(f"Data file not found: {args.data_path}")
        return
    
    try:
        # 创建增强的测试器
        tester = NoTrainingRetrievalTester(
            data_path=args.data_path,
            molformer_model_path=args.molformer_model_path,
            decode_model_path=args.decode_model_path,
            output_dir=args.output_dir,
            device=device,
            random_seed=args.random_seed,
            visualization_methods=args.visualization_methods,
            remove_drug_duplicates=args.remove_drug_duplicates,
            duplicate_threshold=args.duplicate_threshold,
            dose_values=args.dose_values
        )
        
        # 运行完整分析
        results = tester.run_complete_analysis()
        
        # 保存结果
        results_file = tester.save_results(results)
        
        logger.info("\n" + "=" * 80)
        logger.info("🎉 ENHANCED NO-TRAINING RETRIEVAL ANALYSIS COMPLETED!")
        logger.info("=" * 80)
        logger.info(f"📊 Results saved to: {results_file}")
        logger.info(f"📁 Output directory: {args.output_dir}")
        
        # 打印关键结果摘要
        if 'drug_category_retrieval' in results and 'embedding_results' in results['drug_category_retrieval']:
            logger.info("\n🎯 Key Retrieval Performance Summary:")
            embedding_results = results['drug_category_retrieval']['embedding_results']
            
            for embedding_name, embedding_result in embedding_results.items():
                metrics = embedding_result.get('metrics', {})
                if metrics:
                    logger.info(f"  {embedding_name.upper()}:")
                    logger.info(f"    Recall@1: {metrics.get('recall_at_1', 0):.4f}")
                    logger.info(f"    Recall@5: {metrics.get('recall_at_5', 0):.4f}")
                    logger.info(f"    mAP: {metrics.get('mean_average_precision', 0):.4f}")
                    logger.info(f"    Enrichment: {metrics.get('enrichment_factor', 0):.4f}")
        
        logger.info("=" * 80)
        
    except Exception as e:
        logger.error(f"Analysis failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
