"""
ËôöÊãüÁ≠õÈÄâÊó†ËÆ≠ÁªÉÁâàÊú¨Ê£ÄÁ¥¢ÊµãËØï
Áõ¥Êé•‰ΩøÁî®MolformerÂíåDECODEÁöÑembeddingËøõË°åÂèØËßÜÂåñÂíåÊ£ÄÁ¥¢‰ªªÂä°
"""

import os
import sys
import logging
import pandas as pd
import numpy as np
import torch
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.preprocessing import LabelEncoder
import umap
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
import argparse
import json
from datetime import datetime
import yaml
import warnings
warnings.filterwarnings('ignore')

# Ê∑ªÂä†È°πÁõÆË∑ØÂæÑ
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

# ËÆæÁΩÆÊó•Âøó
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ËÆæÁΩÆmatplotlibÂ≠ó‰Ωì
plt.rcParams['font.family'] = 'Times New Roman'
plt.rcParams['font.size'] = 12
sns.set_style("whitegrid")

# È¢úËâ≤ÈÖçÁΩÆ
COLORS = {
    'positive': '#e23e57',
    'negative': '#3f72af', 
    'targeted_cancer': '#FF6B6B',
    'chemo': '#4ECDC4',
    'noncancer': '#45B7D1',
    'background': '#lightgray'
}

class NoTrainingRetrievalTester:
    """Êó†ËÆ≠ÁªÉÁâàÊú¨Ê£ÄÁ¥¢ÊµãËØïÂô®"""
    
    def __init__(
        self,
        data_path: str,
        molformer_model_path: str = './Molformer/',
        decode_model_path: str = None,
        output_dir: str = 'results/no_training_retrieval',
        device: str = 'cuda' if torch.cuda.is_available() else 'cpu',
        random_seed: int = 42,
        visualization_methods: List[str] = ['tsne', 'umap'],
        remove_drug_duplicates: bool = False,
        duplicate_threshold: float = 1e-6,
        dose_values: List[float] = [1.0, 10.0], 
        **kwargs
    ):
        self.data_path = data_path
        self.molformer_model_path = molformer_model_path
        self.decode_model_path = decode_model_path
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        self.device = device
        self.random_seed = random_seed
        self.visualization_methods = visualization_methods
        self.remove_drug_duplicates = remove_drug_duplicates
        self.duplicate_threshold = duplicate_threshold
        self.dose_values = dose_values

        self._init_models()

        self.data = self._load_data()
        
        logger.info(f"No Training Retrieval Tester initialized:")
        logger.info(f"  Data path: {data_path}")
        logger.info(f"  Output dir: {output_dir}")
        logger.info(f"  Device: {device}")
        logger.info(f"  Visualization methods: {visualization_methods}")
        logger.info(f"  Data samples: {len(self.data)}")
        logger.info(f"  Remove drug duplicates: {remove_drug_duplicates}")
        logger.info(f"  Dose values for DECODE: {dose_values}")
    
    def _init_models(self):
        """ÂàùÂßãÂåñMolformerÂíåDECODEÊ®°Âûã"""
        try:
            from transformers import AutoTokenizer, AutoModel

            logger.info("Loading Molformer model...")
            self.molformer_tokenizer = AutoTokenizer.from_pretrained(
                self.molformer_model_path, trust_remote_code=True
            )
            self.molformer_model = AutoModel.from_pretrained(
                self.molformer_model_path, trust_remote_code=True
            ).to(self.device)
            self.molformer_model.eval()
            
            logger.info("‚úÖ Molformer model loaded successfully")
            
        except Exception as e:
            logger.error(f"‚ùå Failed to load Molformer: {e}")
            raise
        
        self.decode_model = None
        if self.decode_model_path:
            try:
                logger.info("Loading DECODE (MultiModalMOAPredictor) model...")
                self.decode_model = self._load_decode_model()
                if self.decode_model:
                    self.decode_model = self.decode_model.to(self.device)
                    self.decode_model.eval()
                    logger.info("‚úÖ DECODE model loaded successfully")
                else:
                    logger.warning("‚ö†Ô∏è DECODE model loading returned None")
            except Exception as e:
                logger.warning(f"‚ö†Ô∏è Failed to load DECODE: {e}")
                self.decode_model = None
    
    def _load_decode_model(self):
        """Âä†ËΩΩDECODEÊ®°ÂûãÔºàÂç≥MultiModalMOAPredictorÔºâ"""
        try:
            if os.path.exists(self.decode_model_path):
                if self.decode_model_path.endswith('.ckpt'):
                    from models.distangle_multimodal.distangle_multimodal_moa_predictor import MultiModalMOAPredictor

                    model = MultiModalMOAPredictor.load_from_checkpoint(
                        self.decode_model_path, 
                        map_location=self.device
                    )
                    return model
                else:
                    logger.warning(f"Unsupported DECODE model format: {self.decode_model_path}")
                    return None
            else:
                logger.warning(f"DECODE model file not found: {self.decode_model_path}")
                return None
                
        except Exception as e:
            logger.warning(f"Failed to load DECODE model: {e}")
            return None
    
    def _load_data(self) -> pd.DataFrame:
        """Âä†ËΩΩÊï∞ÊçÆ"""
        logger.info(f"Loading data from {self.data_path}")
        
        if self.data_path.endswith('.csv'):
            data = pd.read_csv(self.data_path)
        elif self.data_path.endswith('.xlsx'):
            data = pd.read_excel(self.data_path)
        else:
            raise ValueError(f"Unsupported file format: {self.data_path}")
        
        logger.info(f"Loaded {len(data)} samples")
        logger.info(f"Columns: {list(data.columns)}")
        
        # ÂéªÈáçÂ§ÑÁêÜÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
        if self.remove_drug_duplicates:
            data = self._remove_duplicate_drugs_from_dataframe(data)
        
        return data
    
    def _remove_duplicate_drugs_from_dataframe(self, data: pd.DataFrame) -> pd.DataFrame:
        """‰ªéDataFrame‰∏≠ÁßªÈô§ÈáçÂ§çËçØÁâ©"""
        logger.info("üîç Ê£ÄÊµãÂπ∂ÁßªÈô§ÈáçÂ§çËçØÁâ©...")
        
        original_count = len(data)
        
        # Â∞ùËØïÂü∫‰∫éSMILESÂéªÈáç
        smiles_columns = ['smiles', 'SMILES', 'canonical_smiles', 'Metadata_SMILES']
        smiles_column = None
        
        for col in smiles_columns:
            if col in data.columns:
                smiles_column = col
                break
        
        if smiles_column:
            logger.info(f"üß™ Âü∫‰∫éSMILESÂàóÂéªÈáç: {smiles_column}")
            data_deduplicated = data.drop_duplicates(subset=[smiles_column], keep='first')
        else:
            logger.warning("‚ö†Ô∏è Êú™ÊâæÂà∞SMILESÂàóÔºåÊó†Ê≥ïÂéªÈáç")
            return data
        
        removed_count = original_count - len(data_deduplicated)

        return data_deduplicated
    
    def extract_molformer_embeddings(self, smiles_list: List[str], batch_size: int = 32) -> torch.Tensor:
        """ÊèêÂèñMolformer embeddings"""
        logger.info(f"Extracting Molformer embeddings for {len(smiles_list)} molecules...")
        
        all_embeddings = []
        
        with torch.no_grad():
            for i in range(0, len(smiles_list), batch_size):
                batch_smiles = smiles_list[i:i+batch_size]
                
                # Tokenize
                encoded = self.molformer_tokenizer(
                    batch_smiles,
                    return_tensors='pt',
                    padding=True,
                    truncation=True,
                    max_length=512
                ).to(self.device)
                
                # Forward pass
                outputs = self.molformer_model(**encoded)
                
                embeddings = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_dim]
                all_embeddings.append(embeddings.cpu())
                
                if (i // batch_size + 1) % 10 == 0:
                    logger.info(f"  Processed {i + len(batch_smiles)}/{len(smiles_list)} molecules")
        
        embeddings = torch.cat(all_embeddings, dim=0)
        logger.info(f"Extracted embeddings shape: {embeddings.shape}")
        
        return embeddings
    
    def extract_decode_embeddings(self, smiles_list: List[str], batch_size: int = 32) -> Optional[torch.Tensor]:
        if self.decode_model is None:
            logger.warning("DECODE model not available")
            return None
        
        logger.info(f"Extracting DECODE embeddings for {len(smiles_list)} molecules...")
        logger.info("Following SimplifiedDisentangledVirtualScreeningModule feature extraction pipeline:")
        logger.info("Step 1: Extract Molformer drug features")
        logger.info("Step 2: Use both_missing scenario to get disentangled features")
        logger.info("Step 3: Average across multiple dose values")
        
        all_embeddings = []
        
        with torch.no_grad():
            for i in range(0, len(smiles_list), batch_size):
                batch_smiles = smiles_list[i:i+batch_size]
                
                try:
                    molformer_drug_features = self._extract_molformer_drug_features_for_decode(batch_smiles)

                    batch_embeddings = self._extract_disentangled_features_from_molformer(
                        molformer_drug_features, len(batch_smiles)
                    )
                    
                    if batch_embeddings is not None:
                        all_embeddings.append(batch_embeddings.cpu())
                    
                    if (i // batch_size + 1) % 10 == 0:
                        logger.info(f"  Processed {i + len(batch_smiles)}/{len(smiles_list)} molecules")
                        
                except Exception as e:
                    logger.error(f"Error processing batch {i//batch_size}: {e}")
                    continue
        
        if all_embeddings:
            embeddings = torch.cat(all_embeddings, dim=0)
            logger.info(f"Extracted DECODE embeddings shape: {embeddings.shape}")
            return embeddings
        else:
            logger.warning("No DECODE embeddings extracted")
            return None
    
    def _extract_molformer_drug_features_for_decode(self, smiles_list: List[str]) -> torch.Tensor:
        """‰∏∫DECODEÊèêÂèñMolformerËçØÁâ©ÁâπÂæÅÔºàÊ®°‰ªøSimplifiedDisentangledVirtualScreeningModuleÁöÑ_encode_smiles_to_drug_featuresÊñπÊ≥ïÔºâ"""

        encoded = self.molformer_tokenizer(
            smiles_list,
            return_tensors='pt',
            padding=True,
            truncation=True,
            max_length=512
        ).to(self.device)

        outputs = self.molformer_model(**encoded)

        drug_features = outputs.last_hidden_state[:, 0, :]  # [batch_size, hidden_dim]
        
        logger.debug(f"Extracted Molformer drug features shape: {drug_features.shape}")
        return drug_features
    
    def _extract_disentangled_features_from_molformer(self, drug_features: torch.Tensor, batch_size: int) -> Optional[torch.Tensor]:
        """‰ΩøÁî®Ëß£ËÄ¶Ê®°Âûã‰ªéMolformerÁâπÂæÅÊèêÂèñboth_missingÂú∫ÊôØÁöÑÁâπÂæÅÔºàÊ®°‰ªøSimplifiedDisentangledVirtualScreeningModuleÁöÑ_extract_disentangled_featuresÊñπÊ≥ïÔºâ"""
        device = drug_features.device

        all_disentangled_features = []
        
        try:
            for dose_value in self.dose_values:
                logger.debug(f"Processing dose value: {dose_value}")
     
                batch_data = {
                    'drug': drug_features,
                    'dose': torch.full((batch_size, 1), dose_value).to(device),
                    'rna': torch.zeros(batch_size, self.decode_model.rna_dim).to(device), 
                    'pheno': torch.zeros(batch_size, self.decode_model.pheno_dim).to(device) 
                }

                predictions = self.decode_model(batch_data, missing_scenarios=['both_missing'])
                
                if 'both_missing' not in predictions:
                    logger.warning(f"both_missing scenario not found in predictions for dose {dose_value}")
                    continue
                
                both_missing_result = predictions['both_missing']

                if 'fused_features' in both_missing_result:
                    fused_features = both_missing_result['fused_features']
                    all_disentangled_features.append(fused_features)
                    logger.debug(f"Extracted fused_features shape for dose {dose_value}: {fused_features.shape}")
                else:
                    logger.warning(f"fused_features not found in both_missing result for dose {dose_value}")

            if len(all_disentangled_features) > 1:
                final_disentangled_features = torch.stack(all_disentangled_features, dim=0).mean(dim=0)
                logger.debug(f"Averaged features across {len(all_disentangled_features)} dose values")
            elif len(all_disentangled_features) == 1:
                final_disentangled_features = all_disentangled_features[0]
                logger.debug("Using single dose features")
            else:
                logger.error("No disentangled features extracted for any dose value")
                return None
            
            return final_disentangled_features
            
        except Exception as e:
            logger.error(f"Error in _extract_disentangled_features_from_molformer: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def create_binary_classification_visualization(self, embeddings: torch.Tensor, 
                                                 labels: np.ndarray, 
                                                 method: str = 'tsne') -> plt.Figure:
        """ÂàõÂª∫‰∫åÂÖÉÂàÜÁ±ªÂèØËßÜÂåñ"""
        logger.info(f"Creating binary classification visualization using {method.upper()}...")
        
        embeddings_np = embeddings.cpu().numpy()
        if method == 'tsne':
            reducer = TSNE(n_components=2, perplexity=30, random_state=self.random_seed)
        elif method == 'umap':
            reducer = umap.UMAP(n_components=2, random_state=self.random_seed)
        else:
            raise ValueError(f"Unsupported method: {method}")

        if embeddings_np.shape[1] > 50:
            pca = PCA(n_components=50, random_state=self.random_seed)
            embeddings_np = pca.fit_transform(embeddings_np)
            logger.info(f"PCA reduced features from {embeddings.shape[1]} to 50 dimensions")
        
        reduced_features = reducer.fit_transform(embeddings_np)

        fig, ax = plt.subplots(figsize=(10, 8))

        positive_mask = labels == 1
        negative_mask = labels == 0

        ax.scatter(reduced_features[negative_mask, 0], reduced_features[negative_mask, 1],
                  c=COLORS['negative'], alpha=0.6, s=50, label=f'Negative (n={negative_mask.sum()})')

        ax.scatter(reduced_features[positive_mask, 0], reduced_features[positive_mask, 1],
                  c=COLORS['positive'], alpha=0.8, s=60, label=f'Positive (n={positive_mask.sum()})')
        
        ax.set_title(f'Binary Classification Visualization ({method.upper()})\n'
                    f'Molformer Embeddings', fontsize=14, fontweight='bold')
        ax.set_xlabel(f'{method.upper()}-1', fontsize=12)
        ax.set_ylabel(f'{method.upper()}-2', fontsize=12)
        ax.legend(fontsize=10)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig
    
    def create_moa_visualization(self, embeddings: torch.Tensor, 
                               moa_labels: List[str], 
                               method: str = 'tsne',
                               max_moas: int = 10) -> plt.Figure:
        """ÂàõÂª∫MOAÁ±ªÂà´ÂèØËßÜÂåñ"""
        logger.info(f"Creating MOA visualization using {method.upper()}...")
        
        embeddings_np = embeddings.cpu().numpy()
        

        label_encoder = LabelEncoder()
        encoded_moa_labels = label_encoder.fit_transform(moa_labels)
        
        logger.info(f"MOAÁ±ªÂà´ÁºñÁ†Å:")
        for i, moa in enumerate(label_encoder.classes_):
            count = (encoded_moa_labels == i).sum()
            logger.info(f"  {i}: {moa} ({count} samples)")
        

        if method == 'tsne':
            reducer = TSNE(n_components=2, perplexity=30, random_state=self.random_seed)
        elif method == 'umap':
            reducer = umap.UMAP(n_components=2, random_state=self.random_seed)
        else:
            raise ValueError(f"Unsupported method: {method}")
        
        if embeddings_np.shape[1] > 50:
            pca = PCA(n_components=50, random_state=self.random_seed)
            embeddings_np = pca.fit_transform(embeddings_np)
        
        reduced_features = reducer.fit_transform(embeddings_np)

        unique_moas, counts = np.unique(encoded_moa_labels, return_counts=True)
        
        top_moa_indices = np.argsort(counts)[::-1][:max_moas]
        top_moa_codes = unique_moas[top_moa_indices]
        

        fig, ax = plt.subplots(figsize=(12, 9))
        

        colors = plt.cm.tab10(np.linspace(0, 1, len(top_moa_codes)))
        
        other_mask = ~np.isin(encoded_moa_labels, top_moa_codes)
        if other_mask.sum() > 0:
            ax.scatter(reduced_features[other_mask, 0], reduced_features[other_mask, 1],
                      c=COLORS['background'], alpha=0.4, s=30, label='Other MOAs')

        for i, moa_code in enumerate(top_moa_codes):
            moa_mask = encoded_moa_labels == moa_code
            count = moa_mask.sum()
            moa_name = label_encoder.classes_[moa_code]
            
            ax.scatter(reduced_features[moa_mask, 0], reduced_features[moa_mask, 1],
                      c=[colors[i]], alpha=0.8, s=60, 
                      label=f'{moa_name} (n={count})')
        
        ax.set_title(f'MOA Classification Visualization ({method.upper()})\n'
                    f'Top {len(top_moa_codes)} MOAs - Molformer Embeddings', 
                    fontsize=14, fontweight='bold')
        ax.set_xlabel(f'{method.upper()}-1', fontsize=12)
        ax.set_ylabel(f'{method.upper()}-2', fontsize=12)
        ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        return fig
    
    def run_drug_category_retrieval(self) -> Dict[str, Any]:
        logger.info("üöÄ Starting enhanced drug category retrieval task...")
        logger.info("Following SimplifiedDisentangledVirtualScreeningModule pipeline for DECODE features")
        logger.info("Using label100=1 as ground truth for accuracy assessment")

        required_columns = ['smiles', 'label100']
        missing_columns = [col for col in required_columns if col not in self.data.columns]
        if missing_columns:
            logger.error(f"Missing required columns: {missing_columns}")
            return {}

        drug_category_column = None
        possible_category_columns = ['drug_category', 'category', 'Drug_Category', 'type']
        for col in possible_category_columns:
            if col in self.data.columns:
                drug_category_column = col
                break
        
        if drug_category_column is None:
            logger.warning("No drug category column found, creating artificial categories based on activity")
            self.data['drug_category'] = self.data.get('label100', 0).apply(
                lambda x: 'targeted cancer' if x == 1 else 'noncancer'
            )
            drug_category_column = 'drug_category'

        smiles_list = self.data['smiles'].tolist()
        drug_categories = self.data[drug_category_column].tolist()
        labels_100 = self.data['label100'].values  

        cancer_drug_mask = []
        for cat in drug_categories:
            cat_lower = str(cat).lower()
            cancer_drug_mask.append(any(term in cat_lower for term in ['targeted cancer', 'chemo']))
        
        cancer_drug_mask = np.array(cancer_drug_mask)

        positive_query_mask = cancer_drug_mask & (labels_100 == 1)
        negative_samples_mask = labels_100 == 0  
        
        logger.info(f"Cancer drug samples: {cancer_drug_mask.sum()}")
        logger.info(f"Positive query samples (cancer drugs with label100=1): {positive_query_mask.sum()}")
        logger.info(f"Negative database samples (label100=0): {negative_samples_mask.sum()}")
        
        if positive_query_mask.sum() == 0:
            logger.error("No positive query samples found (cancer drugs with label100=1)")
            return {}
        
        if negative_samples_mask.sum() == 0:
            logger.error("No negative database samples found (label100=0)")
            return {}

        logger.info("Extracting Molformer embeddings...")
        molformer_embeddings = self.extract_molformer_embeddings(smiles_list)
        
        decode_embeddings = None
        if self.decode_model:
            logger.info("Extracting DECODE embeddings using SimplifiedDisentangledVirtualScreeningModule pipeline...")
            decode_embeddings = self.extract_decode_embeddings(smiles_list)
        
        if decode_embeddings is None:
            logger.error("DECODE model is required for this analysis but not available")
            return {}
        
        results = {}

        embedding_types = [
            ('molformer', molformer_embeddings),
            ('decode', decode_embeddings),
            ('combined', torch.cat([molformer_embeddings, decode_embeddings], dim=1))
        ]
        
        for embedding_name, embeddings in embedding_types:
            logger.info(f"\nüî¨ Processing {embedding_name} embeddings...")

            query_embeddings = embeddings[positive_query_mask]
            database_embeddings = embeddings[negative_samples_mask]

            query_labels = np.ones(query_embeddings.shape[0])  
            database_labels = np.zeros(database_embeddings.shape[0])  
            
            logger.info(f"Query embeddings: {query_embeddings.shape}")
            logger.info(f"Database embeddings: {database_embeddings.shape}")
            

            if len(query_embeddings) > 0 and len(database_embeddings) > 0:
                metrics = self.compute_retrieval_metrics(
                    query_embeddings, database_embeddings,
                    query_labels, database_labels
                )
                
                logger.info(f"{embedding_name} retrieval metrics:")
                for metric_name, metric_value in metrics.items():
                    logger.info(f"  {metric_name}: {metric_value:.4f}")
            else:
                logger.warning(f"Insufficient data for {embedding_name} retrieval task")
                metrics = {}
            
            results[embedding_name] = {
                'metrics': metrics,
                'query_samples': positive_query_mask.sum(),
                'database_samples': negative_samples_mask.sum()
            }
        
        visualizations = {}
        for method in self.visualization_methods:
            try:
                fig = self.create_dual_model_visualization(
                    molformer_embeddings, decode_embeddings, labels_100, method
                )
                
                viz_file = self.output_dir / f'dual_model_retrieval_{method}.png'
                fig.savefig(viz_file, dpi=300, bbox_inches='tight')
                plt.close(fig)
                visualizations[method] = str(viz_file)
                logger.info(f"Dual model {method.upper()} visualization saved to: {viz_file}")
            except Exception as e:
                logger.error(f"Error creating {method} visualization: {e}")
        
        return {
            'embedding_results': results,
            'visualizations': visualizations,
            'data_stats': {
                'total_samples': len(self.data),
                'cancer_drug_samples': cancer_drug_mask.sum(),
                'positive_query_samples': positive_query_mask.sum(),
                'negative_database_samples': negative_samples_mask.sum()
            }
        }
    
    def create_dual_model_visualization(self, molformer_embeddings: torch.Tensor,
                                      decode_embeddings: torch.Tensor,
                                      labels: np.ndarray,
                                      method: str = 'tsne') -> plt.Figure:
        logger.info(f"Creating dual model visualization using {method.upper()}...")

        fig, axes = plt.subplots(1, 2, figsize=(16, 8))
        
        embeddings_list = [
            (molformer_embeddings, "Molformer", axes[0]),
            (decode_embeddings, "DECODE", axes[1])
        ]
        
        for embeddings, title, ax in embeddings_list:
            embeddings_np = embeddings.cpu().numpy()

            if method == 'tsne':
                reducer = TSNE(n_components=2, perplexity=30, random_state=self.random_seed)
            elif method == 'umap':
                reducer = umap.UMAP(n_components=2, random_state=self.random_seed)
            else:
                raise ValueError(f"Unsupported method: {method}")

            if embeddings_np.shape[1] > 50:
                pca = PCA(n_components=50, random_state=self.random_seed)
                embeddings_np = pca.fit_transform(embeddings_np)
            
            reduced_features = reducer.fit_transform(embeddings_np)

            positive_mask = labels == 1
            negative_mask = labels == 0

            ax.scatter(reduced_features[negative_mask, 0], reduced_features[negative_mask, 1],
                      c=COLORS['negative'], alpha=0.6, s=50, label=f'Negative (n={negative_mask.sum()})')

            ax.scatter(reduced_features[positive_mask, 0], reduced_features[positive_mask, 1],
                      c=COLORS['positive'], alpha=0.8, s=60, label=f'Positive (n={positive_mask.sum()})')
            
            ax.set_title(f'{title} ({method.upper()})', fontsize=14, fontweight='bold')
            ax.set_xlabel(f'{method.upper()}-1', fontsize=12)
            ax.set_ylabel(f'{method.upper()}-2', fontsize=12)
            ax.legend(fontsize=10)
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Dual Model Comparison - Cancer Drug Retrieval ({method.upper()})', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        return fig

    def compute_retrieval_metrics(self, query_features: torch.Tensor, 
                                database_features: torch.Tensor,
                                query_labels: np.ndarray,
                                database_labels: np.ndarray) -> Dict[str, float]:
        """ËÆ°ÁÆóÊ£ÄÁ¥¢ÊåáÊ†á - Êâ©Â±ïÂà∞recall@20"""
        logger.info("Computing retrieval metrics...")

        query_features = F.normalize(query_features, dim=-1)
        database_features = F.normalize(database_features, dim=-1)

        similarity_matrix = torch.mm(query_features, database_features.t())
        
        metrics = {}

        k_values = [1, 5, 10, 15, 20]
        all_recalls = {k: [] for k in k_values}
        all_precisions = {k: [] for k in k_values}
        all_aps = []
        all_rrs = []
        all_enrichments = []
        
        for i in range(len(query_features)):
            query_label = query_labels[i]
            similarities = similarity_matrix[i]
            
            _, sorted_indices = torch.sort(similarities, descending=True)
            retrieved_labels = database_labels[sorted_indices.cpu().numpy()]
            

            relevance = (retrieved_labels == query_label).astype(float)
            num_relevant = relevance.sum()
            
            if num_relevant == 0:
                continue
            
            # Recall@K
            for k in k_values:
                if k <= len(retrieved_labels):
                    recall_k = relevance[:k].sum() / max(num_relevant, 1)
                    all_recalls[k].append(recall_k)
            
            # Precision@K
            for k in k_values:
                if k <= len(retrieved_labels):
                    precision_k = relevance[:k].sum() / k
                    all_precisions[k].append(precision_k)
            
            # Average Precision
            precisions = []
            for j in range(len(retrieved_labels)):
                if relevance[j] == 1:
                    precision_at_j = relevance[:j+1].sum() / (j + 1)
                    precisions.append(precision_at_j)
            
            if precisions:
                ap = np.mean(precisions)
                all_aps.append(ap)
            
            # Reciprocal Rank
            first_relevant = np.where(relevance == 1)[0]
            if len(first_relevant) > 0:
                rr = 1.0 / (first_relevant[0] + 1)
                all_rrs.append(rr)
            
            # Enrichment Factor @10%
            top_10_percent = max(1, int(len(retrieved_labels) * 0.1))
            expected_rate = num_relevant / len(retrieved_labels)
            actual_rate = relevance[:top_10_percent].sum() / top_10_percent
            if expected_rate > 0:
                enrichment = actual_rate / expected_rate
                all_enrichments.append(enrichment)

        for k in k_values:
            if all_recalls[k]:
                metrics[f'recall_at_{k}'] = np.mean(all_recalls[k])
            if all_precisions[k]:
                metrics[f'precision_at_{k}'] = np.mean(all_precisions[k])
        
        if all_aps:
            metrics['mean_average_precision'] = np.mean(all_aps)
        
        if all_rrs:
            metrics['mean_reciprocal_rank'] = np.mean(all_rrs)
        
        if all_enrichments:
            metrics['enrichment_factor'] = np.mean(all_enrichments)
        

        separation_metrics = self._compute_separation_metrics(query_features, database_features)
        metrics.update(separation_metrics)
        
        return metrics

    def _compute_separation_metrics(self, positive_features: torch.Tensor, 
                                  negative_features: torch.Tensor) -> Dict[str, float]:

        pos_center = positive_features.mean(dim=0)
        neg_center = negative_features.mean(dim=0)

        inter_class_distance = torch.norm(pos_center - neg_center).item()

        pos_intra_distance = torch.norm(positive_features - pos_center.unsqueeze(0), dim=1).mean().item()
        neg_intra_distance = torch.norm(negative_features - neg_center.unsqueeze(0), dim=1).mean().item()
        avg_intra_distance = (pos_intra_distance + neg_intra_distance) / 2

        separation_ratio = inter_class_distance / (avg_intra_distance + 1e-8)

        all_features = torch.cat([positive_features, negative_features], dim=0)
        all_labels = torch.cat([
            torch.ones(len(positive_features)), 
            torch.zeros(len(negative_features))
        ], dim=0)

        all_features_norm = F.normalize(all_features, dim=-1)
        similarity_matrix = torch.mm(all_features_norm, all_features_norm.t())
        
        correct_predictions = 0
        total_predictions = len(all_features)
        
        for i in range(len(all_features)):
            similarities = similarity_matrix[i]
            similarities[i] = -1 
            
            nearest_neighbor_idx = torch.argmax(similarities).item()
            if all_labels[i] == all_labels[nearest_neighbor_idx]:
                correct_predictions += 1
        
        nearest_neighbor_accuracy = correct_predictions / total_predictions
        
        return {
            'inter_class_distance': inter_class_distance,
            'avg_intra_class_distance': avg_intra_distance,
            'separation_ratio': separation_ratio,
            'nearest_neighbor_accuracy': nearest_neighbor_accuracy
        }

    def run_binary_classification_analysis(self) -> Dict[str, Any]:
        """ËøêË°å‰∫åÂÖÉÂàÜÁ±ªÂàÜÊûê - ÂêåÊó∂Â§ÑÁêÜ‰∏§‰∏™Ê®°Âûã"""

        label_column = None
        possible_label_columns = ['label', 'label100', 'activity', 'active']
        for col in possible_label_columns:
            if col in self.data.columns:
                label_column = col
                break
        
        if label_column is None:
            logger.error(f"No label column found. Looked for: {possible_label_columns}")
            return {}

        smiles_list = self.data['smiles'].tolist()
        labels = self.data[label_column].values

        logger.info("Extracting Molformer embeddings...")
        molformer_embeddings = self.extract_molformer_embeddings(smiles_list)
        
        decode_embeddings = None
        if self.decode_model:
            logger.info("Extracting DECODE embeddings...")
            decode_embeddings = self.extract_decode_embeddings(smiles_list)

        visualizations = {}
        for method in self.visualization_methods:
            try:
                if decode_embeddings is not None:
                    fig = self.create_dual_model_visualization(
                        molformer_embeddings, decode_embeddings, labels, method
                    )
                    viz_file = self.output_dir / f'binary_classification_dual_model_{method}.png'
                    
                    logger.info(f"Binary classification dual model {method.upper()} visualization saved to: {viz_file}")
                else:

                    fig = self.create_binary_classification_visualization(molformer_embeddings, labels, method)
                    viz_file = self.output_dir / f'binary_classification_{method}.png'
                    
                    logger.info(f"Binary classification {method.upper()} visualization saved to: {viz_file}")
                
                fig.savefig(viz_file, dpi=300, bbox_inches='tight')
                plt.close(fig)
                visualizations[method] = str(viz_file)
                
            except Exception as e:
                logger.error(f"Error creating {method} visualization: {e}")

        unique_labels, counts = np.unique(labels, return_counts=True)
        label_distribution = dict(zip(unique_labels.astype(str), counts.astype(int)))
        
        return {
            'visualizations': visualizations,
            'label_distribution': label_distribution,
            'label_column': label_column,
            'models_used': ['molformer', 'decode'] if decode_embeddings is not None else ['molformer']
        }
    
    def run_moa_analysis(self) -> Dict[str, Any]:
        """ËøêË°åMOAÂàÜÊûê - ÂêåÊó∂Â§ÑÁêÜ‰∏§‰∏™Ê®°Âûã"""
        logger.info("üß¨ Starting MOA analysis...")

        moa_column = None
        possible_moa_columns = ['moa', 'MOA', 'mechanism', 'target']
        for col in possible_moa_columns:
            if col in self.data.columns:
                moa_column = col
                break
        
        if moa_column is None:
            logger.warning(f"No MOA column found. Looked for: {possible_moa_columns}")
            return {}
        

        smiles_list = self.data['smiles'].tolist()
        moa_labels = self.data[moa_column].tolist()

        logger.info("Extracting Molformer embeddings...")
        molformer_embeddings = self.extract_molformer_embeddings(smiles_list)
        
        decode_embeddings = None
        if self.decode_model:
            logger.info("Extracting DECODE embeddings...")
            decode_embeddings = self.extract_decode_embeddings(smiles_list)

        visualizations = {}
        for method in self.visualization_methods:
            try:
                if decode_embeddings is not None:
                    fig = self.create_dual_model_moa_visualization(
                        molformer_embeddings, decode_embeddings, moa_labels, method
                    )
                    viz_file = self.output_dir / f'moa_analysis_dual_model_{method}.png'
                    
                    logger.info(f"MOA dual model {method.upper()} visualization saved to: {viz_file}")
                else:
                    fig = self.create_moa_visualization(molformer_embeddings, moa_labels, method)
                    viz_file = self.output_dir / f'moa_analysis_{method}.png'
                    
                    logger.info(f"MOA {method.upper()} visualization saved to: {viz_file}")
                
                fig.savefig(viz_file, dpi=300, bbox_inches='tight')
                plt.close(fig)
                visualizations[method] = str(viz_file)
                
            except Exception as e:
                logger.error(f"Error creating {method} visualization: {e}")
        
        unique_moas, counts = np.unique(moa_labels, return_counts=True)
        moa_distribution = dict(zip(unique_moas.astype(str), counts.astype(int)))
        
        return {
            'visualizations': visualizations,
            'moa_distribution': moa_distribution,
            'moa_column': moa_column,
            'unique_moas': len(unique_moas),
            'models_used': ['molformer', 'decode'] if decode_embeddings is not None else ['molformer']
        }
    
    def create_dual_model_moa_visualization(self, molformer_embeddings: torch.Tensor,
                                          decode_embeddings: torch.Tensor,
                                          moa_labels: List[str],
                                          method: str = 'tsne',
                                          max_moas: int = 10) -> plt.Figure:
        """ÂàõÂª∫ÂèåÊ®°ÂûãMOAÂØπÊØîÂèØËßÜÂåñ"""
        logger.info(f"Creating dual model MOA visualization using {method.upper()}...")

        label_encoder = LabelEncoder()
        encoded_moa_labels = label_encoder.fit_transform(moa_labels)
        
        logger.info(f"MOAÁ±ªÂà´ÁºñÁ†Å:")
        for i, moa in enumerate(label_encoder.classes_):
            count = (encoded_moa_labels == i).sum()
            logger.info(f"  {i}: {moa} ({count} samples)")

        fig, axes = plt.subplots(1, 2, figsize=(20, 9))
        
        embeddings_list = [
            (molformer_embeddings, "Molformer", axes[0]),
            (decode_embeddings, "DECODE", axes[1])
        ]
        
        for embeddings, title, ax in embeddings_list:
            embeddings_np = embeddings.cpu().numpy()
            
            if method == 'tsne':
                reducer = TSNE(n_components=2, perplexity=30, random_state=self.random_seed)
            elif method == 'umap':
                reducer = umap.UMAP(n_components=2, random_state=self.random_seed)
            else:
                raise ValueError(f"Unsupported method: {method}")
 
            if embeddings_np.shape[1] > 50:
                pca = PCA(n_components=50, random_state=self.random_seed)
                embeddings_np = pca.fit_transform(embeddings_np)
            
            reduced_features = reducer.fit_transform(embeddings_np)
            
            unique_moas, counts = np.unique(encoded_moa_labels, return_counts=True)
            
            top_moa_indices = np.argsort(counts)[::-1][:max_moas]
            top_moa_codes = unique_moas[top_moa_indices]
            colors = plt.cm.tab10(np.linspace(0, 1, len(top_moa_codes)))
            
            other_mask = ~np.isin(encoded_moa_labels, top_moa_codes)
            if other_mask.sum() > 0:
                ax.scatter(reduced_features[other_mask, 0], reduced_features[other_mask, 1],
                          c=COLORS['background'], alpha=0.4, s=30, label='Other MOAs')
            
            for i, moa_code in enumerate(top_moa_codes):
                moa_mask = encoded_moa_labels == moa_code
                count = moa_mask.sum()
                moa_name = label_encoder.classes_[moa_code]
                
                ax.scatter(reduced_features[moa_mask, 0], reduced_features[moa_mask, 1],
                          c=[colors[i]], alpha=0.8, s=60, 
                          label=f'{moa_name} (n={count})')
            
            ax.set_title(f'{title} - MOA Classification ({method.upper()})', 
                        fontsize=14, fontweight='bold')
            ax.set_xlabel(f'{method.upper()}-1', fontsize=12)
            ax.set_ylabel(f'{method.upper()}-2', fontsize=12)
            
            # Âõæ‰æãÊîæÂú®Âè≥‰æß
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=9)
            ax.grid(True, alpha=0.3)
        
        plt.suptitle(f'Dual Model MOA Classification Comparison ({method.upper()})\n'
                    f'Top {len(top_moa_codes)} MOAs', 
                    fontsize=16, fontweight='bold')
        plt.tight_layout()
        return fig

    def run_complete_analysis(self) -> Dict[str, Any]:
        logger.info("üöÄ Starting enhanced no-training retrieval analysis...")
        
        results = {
            'analysis_info': {
                'data_path': self.data_path,
                'output_dir': str(self.output_dir),
                'device': self.device,
                'random_seed': self.random_seed,
                'visualization_methods': self.visualization_methods,
                'timestamp': datetime.now().isoformat(),
                'molformer_available': True,
                'decode_available': self.decode_model is not None,
                'remove_drug_duplicates': self.remove_drug_duplicates
            }
        }
        
        try:
            binary_results = self.run_binary_classification_analysis()
            results['binary_classification'] = binary_results
            logger.info("‚úÖ Binary classification analysis completed")
        except Exception as e:
            logger.error(f"‚ùå Binary classification analysis failed: {e}")
        
        try:
            moa_results = self.run_moa_analysis()
            results['moa_analysis'] = moa_results
            logger.info("‚úÖ MOA analysis completed")
        except Exception as e:
            logger.error(f"‚ùå MOA analysis failed: {e}")
        try:
            drug_category_results = self.run_drug_category_retrieval()
            results['drug_category_retrieval'] = drug_category_results
            logger.info("‚úÖ Enhanced drug category retrieval completed")
        except Exception as e:
            logger.error(f"‚ùå Drug category retrieval failed: {e}")
        
        return results
    
    def save_results(self, results: Dict[str, Any]) -> str:
        logger.info("üíæ Saving enhanced results...")
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        results_file = self.output_dir / f'no_training_retrieval_results_{timestamp}.json'
        
        with open(results_file, 'w') as f:
            json.dump(results, f, indent=2, default=str)
        self._create_enhanced_summary_report(results, timestamp)
        
        logger.info(f"Results saved to: {results_file}")
        return str(results_file)
    
    def _create_enhanced_summary_report(self, results: Dict[str, Any], timestamp: str):
        report_file = self.output_dir / f'enhanced_analysis_summary_{timestamp}.txt'
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("=" * 80 + "\n")
            f.write("ENHANCED NO-TRAINING RETRIEVAL ANALYSIS SUMMARY REPORT\n")
            f.write("=" * 80 + "\n")
            f.write(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"Data path: {self.data_path}\n")
            f.write(f"Total samples: {len(self.data)}\n")
            f.write(f"Molformer available: {results['analysis_info']['molformer_available']}\n")
            f.write(f"DECODE available: {results['analysis_info']['decode_available']}\n")
            f.write(f"Drug duplicates removed: {results['analysis_info']['remove_drug_duplicates']}\n")
            f.write(f"DECODE dose values: {self.dose_values}\n")
            f.write(f"DECODE pipeline: SimplifiedDisentangledVirtualScreeningModule-based\n")
            f.write(f"Retrieval evaluation: Query=cancer drugs with label100=1, Database=samples with label100=0\n\n")
            
            # ËçØÁâ©Á±ªÂà´Ê£ÄÁ¥¢ÁªìÊûúÂØπÊØî
            if 'drug_category_retrieval' in results and 'embedding_results' in results['drug_category_retrieval']:
                f.write("DUAL MODEL RETRIEVAL RESULTS COMPARISON\n")
                f.write("-" * 50 + "\n")
                
                embedding_results = results['drug_category_retrieval']['embedding_results']
                
                f.write("Model Performance Comparison:\n")
                f.write(f"{'Model':<15} {'Recall@1':<10} {'Recall@5':<10} {'Recall@20':<10} {'NN_Acc':<10} {'Sep_Ratio':<12}\n")
                f.write("-" * 80 + "\n")
                
                for embedding_name, embedding_result in embedding_results.items():
                    metrics = embedding_result.get('metrics', {})
                    recall_1 = metrics.get('recall_at_1', 0)
                    recall_5 = metrics.get('recall_at_5', 0)
                    recall_20 = metrics.get('recall_at_20', 0)
                    nn_acc = metrics.get('nearest_neighbor_accuracy', 0)
                    sep_ratio = metrics.get('separation_ratio', 0)
                    
                    f.write(f"{embedding_name:<15} {recall_1:<10.4f} {recall_5:<10.4f} {recall_20:<10.4f} {nn_acc:<10.4f} {sep_ratio:<12.4f}\n")
                
                # ÊâæÂá∫ÊúÄ‰Ω≥Ê®°Âûã
                best_model = None
                best_nn_acc = 0
                for embedding_name, embedding_result in embedding_results.items():
                    nn_acc = embedding_result.get('metrics', {}).get('nearest_neighbor_accuracy', 0)
                    if nn_acc > best_nn_acc:
                        best_nn_acc = nn_acc
                        best_model = embedding_name
                
                if best_model:
                    f.write(f"\nBest performing model: {best_model} (NN Accuracy: {best_nn_acc:.4f})\n")
                
                # Êï∞ÊçÆÁªüËÆ°
                if 'data_stats' in results['drug_category_retrieval']:
                    stats = results['drug_category_retrieval']['data_stats']
                    f.write(f"\nData Distribution:\n")
                    f.write(f"  Total samples: {stats.get('total_samples', 0)}\n")
                    f.write(f"  Cancer drug samples: {stats.get('cancer_drug_samples', 0)}\n")
                    f.write(f"  Positive query samples (cancer + label100=1): {stats.get('positive_query_samples', 0)}\n")
                    f.write(f"  Negative database samples (label100=0): {stats.get('negative_database_samples', 0)}\n")
            
            f.write("\n" + "=" * 80 + "\n")
            f.write("KEY FINDINGS:\n")
            f.write("- Both Molformer and DECODE models evaluated simultaneously\n")
            f.write("- Retrieval accuracy determined by label100=1 ground truth\n")
            f.write("- Query samples: cancer drugs with confirmed activity (label100=1)\n")
            f.write("- Database samples: all inactive compounds (label100=0)\n")
            f.write("- Separation metrics measure feature space discrimination\n")
            f.write("- Nearest neighbor accuracy indicates clustering quality\n")
            f.write("- DECODE features extracted using both_missing scenario\n")
            f.write("- Combined features may enhance discrimination capability\n")
            if results['analysis_info']['decode_available']:
                f.write("- DECODE model successfully integrated for comparison\n")
            else:
                f.write("- DECODE model not available - using Molformer only\n")
            f.write("=" * 80 + "\n")
        
        logger.info(f"üìÑ Enhanced summary report saved to: {report_file}")


def main():
    """‰∏ªÂáΩÊï∞"""
    parser = argparse.ArgumentParser(description='Enhanced No-Training Retrieval Analysis for Virtual Screening')
    parser.add_argument('--data_path', type=str, 
                       default='preprocessed_data/Virtual_screening/Cancer/ChEMBL-Cancer_processed_ac.csv')
    parser.add_argument('--molformer_model_path', type=str, 
                       default='./Molformer/',
                       help='Path to Molformer model')
    parser.add_argument('--decode_model_path', type=str,
                       default='results_distangle/multimodal_lincs_plate/20250825_212437/split_0/stage1/checkpoints_stage1/stage1-multimodal-moa-56-46.405534.ckpt',
                       help='Path to DECODE (MultiModalMOAPredictor) model')
    parser.add_argument('--output_dir', type=str,
                       default='results/no_training_retrieval',
                       help='Output directory for results')
    parser.add_argument('--device', type=str, default='auto',
                       help='Device to use (auto, cuda, cpu)')
    parser.add_argument('--random_seed', type=int, default=42,
                       help='Random seed for reproducibility')
    parser.add_argument('--visualization_methods', nargs='+',
                       default=['tsne', 'umap'],
                       help='Visualization methods to use')
    parser.add_argument('--remove_drug_duplicates', action='store_true',
                       help='Remove duplicate drug samples')
    parser.add_argument('--duplicate_threshold', type=float, default=1e-6,
                       help='Threshold for duplicate detection')
    parser.add_argument('--dose_values', nargs='+', type=float,
                       default=[1.0, 10.0],
                       help='Dose values for DECODE feature averaging')
    
    args = parser.parse_args()
    
    # ËÆæÁΩÆËÆæÂ§á
    if args.device == 'auto':
        device = 'cuda' if torch.cuda.is_available() else 'cpu'
    else:
        device = args.device
    
    logger.info(f"Using device: {device}")
    logger.info(f"DECODE dose values: {args.dose_values}")
    
    # Ê£ÄÊü•Êï∞ÊçÆÊñá‰ª∂
    if not os.path.exists(args.data_path):
        logger.error(f"Data file not found: {args.data_path}")
        return
    
    try:
        # ÂàõÂª∫Â¢ûÂº∫ÁöÑÊµãËØïÂô®
        tester = NoTrainingRetrievalTester(
            data_path=args.data_path,
            molformer_model_path=args.molformer_model_path,
            decode_model_path=args.decode_model_path,
            output_dir=args.output_dir,
            device=device,
            random_seed=args.random_seed,
            visualization_methods=args.visualization_methods,
            remove_drug_duplicates=args.remove_drug_duplicates,
            duplicate_threshold=args.duplicate_threshold,
            dose_values=args.dose_values
        )
        
        # ËøêË°åÂÆåÊï¥ÂàÜÊûê
        results = tester.run_complete_analysis()
        
        # ‰øùÂ≠òÁªìÊûú
        results_file = tester.save_results(results)
        
        logger.info("\n" + "=" * 80)
        logger.info("üéâ ENHANCED NO-TRAINING RETRIEVAL ANALYSIS COMPLETED!")
        logger.info("=" * 80)
        logger.info(f"üìä Results saved to: {results_file}")
        logger.info(f"üìÅ Output directory: {args.output_dir}")
        
        # ÊâìÂç∞ÂÖ≥ÈîÆÁªìÊûúÊëòË¶Å
        if 'drug_category_retrieval' in results and 'embedding_results' in results['drug_category_retrieval']:
            logger.info("\nüéØ Key Retrieval Performance Summary:")
            embedding_results = results['drug_category_retrieval']['embedding_results']
            
            for embedding_name, embedding_result in embedding_results.items():
                metrics = embedding_result.get('metrics', {})
                if metrics:
                    logger.info(f"  {embedding_name.upper()}:")
                    logger.info(f"    Recall@1: {metrics.get('recall_at_1', 0):.4f}")
                    logger.info(f"    Recall@5: {metrics.get('recall_at_5', 0):.4f}")
                    logger.info(f"    mAP: {metrics.get('mean_average_precision', 0):.4f}")
                    logger.info(f"    Enrichment: {metrics.get('enrichment_factor', 0):.4f}")
        
        logger.info("=" * 80)
        
    except Exception as e:
        logger.error(f"Analysis failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
